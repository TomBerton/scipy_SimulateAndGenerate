{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams['figure.figsize'] = [10, 5]\n",
    "\n",
    "import pdb\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import simpy\n",
    "import random\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, recall_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.under_sampling import NearMiss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Apply SMOTE to generate more examples of low-incidence state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## data sourced from https://archive.ics.uci.edu/ml/machine-learning-databases/cmc/\n",
    "cmc = pd.read_csv(\"cmc.data\", header = None)\n",
    "cmc.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cmc.columns = ['age', 'education', 'husband_education', 'num_children', 'religion', 'works',\n",
    "              'husband_occupation', 'sol_index', 'media_exposure', 'contracep_method']\n",
    "cmc.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(cmc.contracep_method)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "333/(333 + 629 + 511)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "smote_obj = SMOTE()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = cmc.iloc[:, 0:9]\n",
    "y = cmc.iloc[:, 9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## train a classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(21)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = RandomForestClassifier(n_estimators=10)\n",
    "clf.fit(X_train, y_train)\n",
    "clf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix(y_test, clf.predict(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "42  / (35 + 42 + 43)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_smote, y_train_smote = smote_obj.fit_sample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise: examine some feature distibutions post oversampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Does SMOTE improve the model?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.bincount(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(21)\n",
    "clf = RandomForestClassifier(n_estimators=10)\n",
    "clf.fit(X_train_smote, y_train_smote)\n",
    "clf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix(y_test, clf.predict(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "51 / (51 + 33 + 36)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Repeat this analysis with a less balanced data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## data from https://archive.ics.uci.edu/ml/datasets/Bank+Marketing#\n",
    "bank_df = pd.read_csv(\"bank.csv\", index_col=0)\n",
    "print(bank_df.head())\n",
    "print(bank_df.groupby(\"y\").count())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert categories to numeric labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bank_df.default = bank_df.default.map({\"yes\": 1, \"no\": 0})\n",
    "bank_df.housing = bank_df.housing.map({\"yes\": 1, \"no\": 0})\n",
    "bank_df.loan    = bank_df.loan.map   ({\"yes\": 1, \"no\": 0})\n",
    "bank_df.y       = bank_df.y.map      ({\"yes\": 1, \"no\": 0})\n",
    "\n",
    "bank_df.education = bank_df.education.map({\"unknown\": -1, \"primary\": 0, \"secondary\": 1, \"tertiary\": 2})\n",
    "bank_df.marital   = bank_df.marital.map({\"married\": 0, \"single\"   : 1, \"divorced\": 2})\n",
    "bank_df.job = bank_df.job.apply(lambda x: 0 if x == 'unemployed' or x == 'unknown' else 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = bank_df.iloc[:, 0:7]\n",
    "y = bank_df.iloc[:, 7]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = RandomForestClassifier(n_estimators=5)\n",
    "clf.fit(X_train, y_train)\n",
    "clf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix(y_test, clf.predict(X_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise: Oversample the minority class with the SMOTE method and examine whether it has changed the data distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's take a look at the source code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from the source code\n",
    "def _sample(self, X, y):\n",
    "    # FIXME: uncomment in version 0.6\n",
    "    # self._validate_estimator()\n",
    "\n",
    "    X_resampled = X.copy()\n",
    "    y_resampled = y.copy()\n",
    "\n",
    "    for class_sample, n_samples in self.sampling_strategy_.items():\n",
    "        if n_samples == 0:\n",
    "            continue\n",
    "        target_class_indices = np.flatnonzero(y == class_sample)\n",
    "        X_class = safe_indexing(X, target_class_indices)\n",
    "\n",
    "        self.nn_k_.fit(X_class)\n",
    "        nns = self.nn_k_.kneighbors(X_class, return_distance=False)[:, 1:]\n",
    "        X_new, y_new = self._make_samples(X_class, y.dtype, class_sample, ######################\n",
    "                                          X_class, nns, n_samples, 1.0)   ######################\n",
    "\n",
    "        if sparse.issparse(X_new):\n",
    "            X_resampled = sparse.vstack([X_resampled, X_new])\n",
    "            sparse_func = 'tocsc' if X.format == 'csc' else 'tocsr'\n",
    "            X_resampled = getattr(X_resampled, sparse_func)()\n",
    "        else:\n",
    "            X_resampled = np.vstack((X_resampled, X_new))\n",
    "        y_resampled = np.hstack((y_resampled, y_new))\n",
    "\n",
    "    return X_resampled, y_resampled\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _make_samples(self,\n",
    "                  X,\n",
    "                  y_dtype,\n",
    "                  y_type,\n",
    "                  nn_data,\n",
    "                  nn_num,\n",
    "                  n_samples,\n",
    "                  step_size=1.):\n",
    "    \"\"\"A support function that returns artificial samples constructed along\n",
    "    the line connecting nearest neighbours.\n",
    "    Parameters\n",
    "    ----------\n",
    "    X : {array-like, sparse matrix}, shape (n_samples, n_features)\n",
    "        Points from which the points will be created.\n",
    "    y_dtype : dtype\n",
    "        The data type of the targets.\n",
    "    y_type : str or int\n",
    "        The minority target value, just so the function can return the\n",
    "        target values for the synthetic variables with correct length in\n",
    "        a clear format.\n",
    "    nn_data : ndarray, shape (n_samples_all, n_features)\n",
    "        Data set carrying all the neighbours to be used\n",
    "    nn_num : ndarray, shape (n_samples_all, k_nearest_neighbours)\n",
    "        The nearest neighbours of each sample in `nn_data`.\n",
    "    n_samples : int\n",
    "        The number of samples to generate.\n",
    "    step_size : float, optional (default=1.)\n",
    "        The step size to create samples.\n",
    "    Returns\n",
    "    -------\n",
    "    X_new : {ndarray, sparse matrix}, shape (n_samples_new, n_features)\n",
    "        Synthetically generated samples.\n",
    "    y_new : ndarray, shape (n_samples_new,)\n",
    "        Target values for synthetic samples.\n",
    "    \"\"\"\n",
    "    random_state = check_random_state(self.random_state)\n",
    "    samples_indices = random_state.randint(\n",
    "        low=0, high=len(nn_num.flatten()), size=n_samples)\n",
    "    steps = step_size * random_state.uniform(size=n_samples)\n",
    "    rows = np.floor_divide(samples_indices, nn_num.shape[1])        ######################\n",
    "    cols = np.mod(samples_indices, nn_num.shape[1])                 ######################\n",
    "\n",
    "    y_new = np.array([y_type] * len(samples_indices), dtype=y_dtype)\n",
    "\n",
    "    if sparse.issparse(X):\n",
    "        row_indices, col_indices, samples = [], [], []\n",
    "        for i, (row, col, step) in enumerate(zip(rows, cols, steps)):\n",
    "            if X[row].nnz:\n",
    "                sample = self._generate_sample(X, nn_data, nn_num,    ######################\n",
    "                                               row, col, step)        ######################\n",
    "                row_indices += [i] * len(sample.indices)\n",
    "                col_indices += sample.indices.tolist()\n",
    "                samples += sample.data.tolist()\n",
    "        return (sparse.csr_matrix((samples, (row_indices, col_indices)),\n",
    "                                  [len(samples_indices), X.shape[1]],\n",
    "                                  dtype=X.dtype),\n",
    "                y_new)\n",
    "    else:\n",
    "        X_new = np.zeros((n_samples, X.shape[1]), dtype=X.dtype)\n",
    "        for i, (row, col, step) in enumerate(zip(rows, cols, steps)):\n",
    "            X_new[i] = self._generate_sample(X, nn_data, nn_num,\n",
    "                                             row, col, step)\n",
    "        return X_new, y_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _generate_sample(self, X, nn_data, nn_num, row, col, step):\n",
    "    r\"\"\"Generate a synthetic sample.\n",
    "    The rule for the generation is:\n",
    "    .. math::\n",
    "       \\mathbf{s_{s}} = \\mathbf{s_{i}} + \\mathcal{u}(0, 1) \\times\n",
    "       (\\mathbf{s_{i}} - \\mathbf{s_{nn}}) \\,\n",
    "    where \\mathbf{s_{s}} is the new synthetic samples, \\mathbf{s_{i}} is\n",
    "    the current sample, \\mathbf{s_{nn}} is a randomly selected neighbors of\n",
    "    \\mathbf{s_{i}} and \\mathcal{u}(0, 1) is a random number between [0, 1).\n",
    "    Parameters\n",
    "    ----------\n",
    "    X : {array-like, sparse matrix}, shape (n_samples, n_features)\n",
    "        Points from which the points will be created.\n",
    "    nn_data : ndarray, shape (n_samples_all, n_features)\n",
    "        Data set carrying all the neighbours to be used.\n",
    "    nn_num : ndarray, shape (n_samples_all, k_nearest_neighbours)\n",
    "        The nearest neighbours of each sample in `nn_data`.\n",
    "    row : int\n",
    "        Index pointing at feature vector in X which will be used\n",
    "        as a base for creating new sample.\n",
    "    col : int\n",
    "        Index pointing at which nearest neighbor of base feature vector\n",
    "        will be used when creating new sample.\n",
    "    step : float\n",
    "        Step size for new sample.\n",
    "    Returns\n",
    "    -------\n",
    "    X_new : {ndarray, sparse matrix}, shape (n_features,)\n",
    "        Single synthetically generated sample.\n",
    "    \"\"\"\n",
    "    return X[row] - step * (X[row] - nn_data[nn_num[row, col]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
